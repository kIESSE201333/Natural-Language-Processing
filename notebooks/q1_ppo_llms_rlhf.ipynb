{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "491ea75bd37648e2bc7769e7b50ff6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03c546ce64b04a0cb0b06281d384715a",
              "IPY_MODEL_574c4f12051c464a82367d18afeafeb0",
              "IPY_MODEL_316936fed5a548aeb3b0e793f149ad33"
            ],
            "layout": "IPY_MODEL_7cc0b9d24f55467b83b805cd7b7fbaca"
          }
        },
        "03c546ce64b04a0cb0b06281d384715a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6df5b8a164a54fb9bd63eee035fe98e5",
            "placeholder": "​",
            "style": "IPY_MODEL_4e989e08dc52438d95a991ba441a49ec",
            "value": "Training:  62%"
          }
        },
        "574c4f12051c464a82367d18afeafeb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f196f4eac44493ea5031fe7c9b2c06f",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51bf2ebe07e842f8bfc1a16871bb4308",
            "value": 93
          }
        },
        "316936fed5a548aeb3b0e793f149ad33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecb070a84ebd47beaf4058299cb7c0b3",
            "placeholder": "​",
            "style": "IPY_MODEL_5aa7e2d331cb41498420aec71f1225ea",
            "value": " 93/150 [05:28&lt;03:15,  3.42s/it, kl=0.4020]"
          }
        },
        "7cc0b9d24f55467b83b805cd7b7fbaca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df5b8a164a54fb9bd63eee035fe98e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e989e08dc52438d95a991ba441a49ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f196f4eac44493ea5031fe7c9b2c06f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51bf2ebe07e842f8bfc1a16871bb4308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecb070a84ebd47beaf4058299cb7c0b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa7e2d331cb41498420aec71f1225ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRR7aieNMlQO",
        "outputId": "4776c336-047a-4d52-fb6f-90d20fcd9769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Found existing installation: transformers 4.51.3\n",
            "Uninstalling transformers-4.51.3:\n",
            "  Successfully uninstalled transformers-4.51.3\n",
            "Found existing installation: datasets 2.14.4\n",
            "Uninstalling datasets-2.14.4:\n",
            "  Successfully uninstalled datasets-2.14.4\n",
            "\u001b[33mWARNING: Skipping trl as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: tqdm 4.67.1\n",
            "Uninstalling tqdm-4.67.1:\n",
            "  Successfully uninstalled tqdm-4.67.1\n",
            "Found existing installation: accelerate 1.6.0\n",
            "Uninstalling accelerate-1.6.0:\n",
            "  Successfully uninstalled accelerate-1.6.0\n",
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Found existing installation: peft 0.15.2\n",
            "Uninstalling peft-0.15.2:\n",
            "  Successfully uninstalled peft-0.15.2\n",
            "Found existing installation: torchao 0.10.0\n",
            "Uninstalling torchao-0.10.0:\n",
            "  Successfully uninstalled torchao-0.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip uninstall -y transformers datasets trl tqdm accelerate numpy pandas peft torchao"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.2\n",
        "!pip install torch==2.2.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers==4.37.2\n",
        "!pip install pandas==2.1.3\n",
        "!pip install datasets==2.16.1\n",
        "!pip install trl==0.7.10\n",
        "!pip install tqdm==4.66.1\n",
        "!pip install accelerate==0.27.2\n",
        "!pip install peft==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmeeyiheMtpq",
        "outputId": "df49e535-73d5-405f-e34f-52e071816278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.2\n",
            "  Downloading numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "db-dtypes 1.4.2 requires pandas>=0.24.2, which is not installed.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, which is not installed.\n",
            "tensorflow-decision-forests 1.11.0 requires pandas, which is not installed.\n",
            "cmdstanpy 1.2.5 requires pandas, which is not installed.\n",
            "cmdstanpy 1.2.5 requires tqdm, which is not installed.\n",
            "holoviews 1.20.2 requires pandas>=1.3, which is not installed.\n",
            "prophet 1.1.6 requires pandas>=1.0.4, which is not installed.\n",
            "prophet 1.1.6 requires tqdm>=4.36.1, which is not installed.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, which is not installed.\n",
            "moviepy 1.0.3 requires tqdm<5.0,>=4.11.2, which is not installed.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, which is not installed.\n",
            "shap 0.47.2 requires pandas, which is not installed.\n",
            "shap 0.47.2 requires tqdm>=4.27.0, which is not installed.\n",
            "bqplot 0.12.44 requires pandas<3.0.0,>=1.0.0, which is not installed.\n",
            "bokeh 3.7.2 requires pandas>=1.2, which is not installed.\n",
            "cufflinks 0.17.3 requires pandas>=0.19.2, which is not installed.\n",
            "dopamine-rl 4.1.2 requires pandas>=0.24.2, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tqdm>=4.64.1, which is not installed.\n",
            "statsmodels 0.14.4 requires pandas!=2.1.0,>=1.4, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires pandas>=1.1.4, which is not installed.\n",
            "geemap 0.35.3 requires pandas, which is not installed.\n",
            "seaborn 0.13.2 requires pandas>=1.2, which is not installed.\n",
            "geopandas 1.0.1 requires pandas>=1.4.0, which is not installed.\n",
            "sentence-transformers 4.1.0 requires torch>=1.11.0, which is not installed.\n",
            "sentence-transformers 4.1.0 requires tqdm, which is not installed.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, which is not installed.\n",
            "hyperopt 0.2.7 requires tqdm, which is not installed.\n",
            "xarray 2025.3.1 requires pandas>=2.1, which is not installed.\n",
            "spacy 3.8.5 requires tqdm<5.0.0,>=4.38.0, which is not installed.\n",
            "panel 1.6.3 requires pandas>=1.2, which is not installed.\n",
            "panel 1.6.3 requires tqdm, which is not installed.\n",
            "tsfresh 0.21.0 requires pandas>=0.25.0, which is not installed.\n",
            "tsfresh 0.21.0 requires tqdm>=4.10.0, which is not installed.\n",
            "libpysal 4.13.0 requires pandas>=1.4, which is not installed.\n",
            "pandas-gbq 0.28.0 requires pandas>=1.1.4, which is not installed.\n",
            "mlxtend 0.23.4 requires pandas>=0.24.2, which is not installed.\n",
            "dask-cuda 25.2.0 requires pandas>=1.3, which is not installed.\n",
            "bigquery-magics 0.9.0 requires pandas>=1.1.0, which is not installed.\n",
            "bigquery-magics 0.9.0 requires tqdm<5.0.0,>=4.7.4, which is not installed.\n",
            "arviz 0.21.0 requires pandas>=1.5.0, which is not installed.\n",
            "yfinance 0.2.59 requires pandas>=1.3.0, which is not installed.\n",
            "tensorflow-datasets 4.9.8 requires tqdm, which is not installed.\n",
            "bigframes 2.1.0 requires pandas>=1.5.3, which is not installed.\n",
            "pymc 5.22.0 requires pandas>=0.24.0, which is not installed.\n",
            "datascience 0.17.6 requires pandas, which is not installed.\n",
            "umap-learn 0.5.7 requires tqdm, which is not installed.\n",
            "torchtune 0.6.1 requires datasets, which is not installed.\n",
            "torchtune 0.6.1 requires tqdm, which is not installed.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, which is not installed.\n",
            "fastai 2.7.19 requires pandas, which is not installed.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, which is not installed.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.2\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.2.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.0%2Bcu118-cp311-cp311-linux_x86_64.whl (811.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.7/811.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.19.3 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.2.0 (from torch==2.2.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "timm 1.0.15 requires torchvision, which is not installed.\n",
            "sentence-transformers 4.1.0 requires tqdm, which is not installed.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, which is not installed.\n",
            "torchtune 0.6.1 requires datasets, which is not installed.\n",
            "torchtune 0.6.1 requires tqdm, which is not installed.\n",
            "fastai 2.7.19 requires pandas, which is not installed.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 torch-2.2.0+cu118 triton-2.2.0\n",
            "Collecting transformers==4.37.2\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (0.5.3)\n",
            "Collecting tqdm>=4.27 (from transformers==4.37.2)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (2025.4.26)\n",
            "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm, tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cmdstanpy 1.2.5 requires pandas, which is not installed.\n",
            "prophet 1.1.6 requires pandas>=1.0.4, which is not installed.\n",
            "shap 0.47.2 requires pandas, which is not installed.\n",
            "dopamine-rl 4.1.2 requires pandas>=0.24.2, which is not installed.\n",
            "panel 1.6.3 requires pandas>=1.2, which is not installed.\n",
            "tsfresh 0.21.0 requires pandas>=0.25.0, which is not installed.\n",
            "bigquery-magics 0.9.0 requires pandas>=1.1.0, which is not installed.\n",
            "torchtune 0.6.1 requires datasets, which is not installed.\n",
            "fastai 2.7.19 requires pandas, which is not installed.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.15.2 tqdm-4.67.1 transformers-4.37.2\n",
            "Collecting pandas==2.1.3\n",
            "  Downloading pandas-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.1.3) (1.26.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.1.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.1.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.1.3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.3) (1.17.0)\n",
            "Downloading pandas-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.3 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.1.3\n",
            "Collecting datasets==2.16.1\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (1.26.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (18.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.16.1)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (2.1.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (0.70.15)\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.16.1) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.16.1) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->datasets==2.16.1) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->datasets==2.16.1) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.16.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.16.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.16.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.16.1) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.16.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.16.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.16.1) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.17.0)\n",
            "Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: pyarrow-hotfix, fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "timm 1.0.15 requires torchvision, which is not installed.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.16.1 fsspec-2023.10.0 pyarrow-hotfix-0.7\n",
            "Collecting trl==0.7.10\n",
            "  Downloading trl-0.7.10-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.7.10) (2.2.0+cu118)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.7.10) (4.37.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.11/dist-packages (from trl==0.7.10) (1.26.2)\n",
            "Collecting accelerate (from trl==0.7.10)\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from trl==0.7.10) (2.16.1)\n",
            "Collecting tyro>=0.5.11 (from trl==0.7.10)\n",
            "  Downloading tyro-0.9.20-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (11.8.86)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.7.10) (2.2.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.7.10) (0.31.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.7.10) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.7.10) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.7.10) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.7.10) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.7.10) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.7.10) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->trl==0.7.10) (4.67.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.7.10) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.7.10) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.10)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.7.10) (4.4.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->trl==0.7.10) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.7.10) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.7.10) (0.7)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.7.10) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.7.10) (2.1.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.7.10) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.7.10) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.7.10) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.7.10) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.7.10) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.7.10) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.7.10) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.7.10) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.7.10) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.7.10) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.31.0->trl==0.7.10) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.7.10) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.7.10) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.7.10) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.31.0->trl==0.7.10) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (2.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->trl==0.7.10) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.7.10) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.7.10) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.7.10) (2025.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.4.0->trl==0.7.10) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.10) (1.17.0)\n",
            "Downloading trl-0.7.10-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.20-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: shtab, tyro, accelerate, trl\n",
            "Successfully installed accelerate-1.6.0 shtab-1.7.2 trl-0.7.10 tyro-0.9.20\n",
            "Collecting tqdm==4.66.1\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "dataproc-spark-connect 0.7.2 requires tqdm>=4.67, but you have tqdm 4.66.1 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.66.1\n",
            "Collecting accelerate==0.27.2\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (2.2.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (0.31.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.8.86)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (4.66.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n",
            "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.6.0\n",
            "    Uninstalling accelerate-1.6.0:\n",
            "      Successfully uninstalled accelerate-1.6.0\n",
            "Successfully installed accelerate-0.27.2\n",
            "Collecting peft==0.10.0\n",
            "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (2.2.0+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (4.37.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (4.66.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.27.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (0.31.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2023.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (1.1.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.8.86)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (2.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.10.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.10.0) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
            "Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: peft\n",
            "Successfully installed peft-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "import transformers\n",
        "print(transformers.__version__)\n",
        "import datasets\n",
        "print(datasets.__version__)\n",
        "import trl\n",
        "print(trl.__version__)\n",
        "import tqdm\n",
        "print(tqdm.__version__)\n",
        "import accelerate\n",
        "print(accelerate.__version__)\n",
        "import numpy\n",
        "print(numpy.__version__)\n",
        "import peft\n",
        "print(peft.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFTPkwYCNdPG",
        "outputId": "86bf1b6d-d1ba-4f3d-cb93-8b67fa8f6216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.0+cu118\n",
            "4.37.2\n",
            "2.16.1\n",
            "0.7.10\n",
            "4.66.1\n",
            "0.27.2\n",
            "1.26.2\n",
            "0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
        "from uuid import uuid4\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jCVTC-JnUmtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetBuilder:\n",
        "    \"\"\"Handles dataset loading and preprocessing for PPO training.\"\"\"\n",
        "    def __init__(self, model_name: str, dataset_name: str = \"imdb\", max_samples: int = 1500):\n",
        "        self.model_name = model_name\n",
        "        self.dataset_name = dataset_name\n",
        "        self.max_samples = max_samples\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "    def _length_sampler(self, min_len: int = 3, max_len: int = 10):\n",
        "        \"\"\"Samples random sequence lengths.\"\"\"\n",
        "        return np.random.randint(min_len, max_len + 1)\n",
        "\n",
        "    def build(self):\n",
        "        \"\"\"Loads and processes IMDB dataset.\"\"\"\n",
        "        ds = load_dataset(self.dataset_name, split=f\"train[:{self.max_samples}]\")\n",
        "        ds = ds.rename_columns({\"text\": \"review\"})\n",
        "        ds = ds.filter(lambda x: len(x[\"review\"]) > 150, batched=False)\n",
        "\n",
        "        def tokenize(sample):\n",
        "            input_ids = self.tokenizer.encode(sample[\"review\"])\n",
        "            cut = self._length_sampler()\n",
        "            sample[\"input_ids\"] = input_ids[:cut]\n",
        "            sample[\"query\"] = self.tokenizer.decode(input_ids[:cut])\n",
        "            return sample\n",
        "\n",
        "        ds = ds.map(tokenize, batched=False)\n",
        "        ds.set_format(type=\"torch\", columns=[\"input_ids\"], output_all_columns=True)\n",
        "        return ds"
      ],
      "metadata": {
        "id": "_PsdsJAVUnu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_collator(batch):\n",
        "    \"\"\"Collates batch data for PPO training.\"\"\"\n",
        "    return {k: [ex[k] for ex in batch] for k in batch[0]}"
      ],
      "metadata": {
        "id": "pr4CcV7hUopa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_sentiment_pipeline(device: str):\n",
        "    \"\"\"Initializes sentiment analysis pipeline for rewards.\"\"\"\n",
        "    return pipeline(\n",
        "        \"sentiment-analysis\",\n",
        "        model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "        device=device\n",
        "    )"
      ],
      "metadata": {
        "id": "nVP26tTDUpfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ppo():\n",
        "    \"\"\"Main PPO training loop.\"\"\"\n",
        "    # Configuration\n",
        "    config = PPOConfig(\n",
        "        model_name=\"gpt2\",\n",
        "        learning_rate=2e-5,\n",
        "        batch_size=16,\n",
        "        mini_batch_size=4,\n",
        "        ppo_epochs=2,\n",
        "        log_with=None,\n",
        "        ratio_threshold=1e10\n",
        "    )\n",
        "\n",
        "    # Setup\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    dataset = DatasetBuilder(config.model_name, max_samples=1500).build()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name).to(device)\n",
        "    ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name).to(device)\n",
        "\n",
        "    ppo_trainer = PPOTrainer(\n",
        "        config, model, ref_model, tokenizer,\n",
        "        dataset=dataset, data_collator=data_collator\n",
        "    )\n",
        "\n",
        "    sentiment_pipe = setup_sentiment_pipeline(device)\n",
        "    sent_kwargs = {\"top_k\": None, \"batch_size\": 8}\n",
        "    max_updates = 150\n",
        "\n",
        "    # Training loop\n",
        "    update_count = 0\n",
        "    progress_bar = tqdm(total=max_updates, desc=\"Training\")\n",
        "\n",
        "    for batch in ppo_trainer.dataloader:\n",
        "        if update_count >= max_updates:\n",
        "            print(f\"Stopping after {max_updates} updates.\")\n",
        "            break\n",
        "\n",
        "        # Prepare queries\n",
        "        queries = [q.to(device) for q in batch[\"input_ids\"]]\n",
        "        query_texts = batch[\"query\"]\n",
        "\n",
        "        # Generate responses\n",
        "        responses = []\n",
        "        for query in queries:\n",
        "            gen_len = np.random.randint(5, 20)\n",
        "            output = ppo_trainer.generate(\n",
        "                query,\n",
        "                max_new_tokens=gen_len,\n",
        "                do_sample=True,\n",
        "                top_p=0.95,\n",
        "                pad_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "            responses.append(output.squeeze()[-gen_len:])\n",
        "\n",
        "        # Decode responses\n",
        "        response_texts = [tokenizer.decode(r, skip_special_tokens=True) for r in responses]\n",
        "        batch[\"response\"] = response_texts\n",
        "\n",
        "        # Compute rewards\n",
        "        full_texts = [q + r for q, r in zip(query_texts, response_texts)]\n",
        "        sentiment_outputs = sentiment_pipe(full_texts, **sent_kwargs)\n",
        "        print(f\"Type of sentiment_outputs: {type(sentiment_outputs)}\")\n",
        "        print(f\"First element of sentiment_outputs: {sentiment_outputs[0]}\")\n",
        "\n",
        "        rewards = []\n",
        "        for output in sentiment_outputs:\n",
        "            pos_dict = next((d for d in output if d[\"label\"] == \"POSITIVE\"), None)\n",
        "            neg_dict = next((d for d in output if d[\"label\"] == \"NEGATIVE\"), None)\n",
        "            score = pos_dict[\"score\"] if pos_dict else (1 - neg_dict[\"score\"] if neg_dict else 0.5)\n",
        "            rewards.append(torch.tensor(score, device=device))\n",
        "\n",
        "        # PPO step\n",
        "        stats = ppo_trainer.step(queries, responses, rewards)\n",
        "        update_count += 1\n",
        "        progress_bar.update(1)\n",
        "        progress_bar.set_postfix({\"kl\": f\"{stats['ppo/mean_scores']:.4f}\"})\n",
        "\n",
        "    # Save model\n",
        "    output_dir = f\"gpt2-imdb-ppo-{str(uuid4())[:8]}\"\n",
        "    model.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    print(f\"Model saved to ./{output_dir}/\")"
      ],
      "metadata": {
        "id": "CKNvJhfGUrG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model_dir: str, prompts: list):\n",
        "    \"\"\"Evaluates the fine-tuned model on sample prompts.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
        "    gen_pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=0 if device.type == \"cuda\" else -1\n",
        "    )\n",
        "    reward_pipe = setup_sentiment_pipeline(device)\n",
        "\n",
        "    for prompt in prompts:\n",
        "        output = gen_pipe(\n",
        "            prompt,\n",
        "            max_new_tokens=30,;\n",
        "            do_sample=True,\n",
        "            top_p=0.95,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )[0][\"generated_text\"]\n",
        "        scores = reward_pipe(output)[0]\n",
        "        pos_score = scores[\"score\"] if scores[\"label\"] == \"POSITIVE\" else 1 - scores[\"score\"]\n",
        "\n",
        "        print(f\"Prompt: {prompt}\")\n",
        "        print(f\"Generated: {output}\")\n",
        "        print(f\"Positive Score: {pos_score:.4f}\\n\")"
      ],
      "metadata": {
        "id": "stKoF9Vlgyp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_ppo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "491ea75bd37648e2bc7769e7b50ff6d2",
            "03c546ce64b04a0cb0b06281d384715a",
            "574c4f12051c464a82367d18afeafeb0",
            "316936fed5a548aeb3b0e793f149ad33",
            "7cc0b9d24f55467b83b805cd7b7fbaca",
            "6df5b8a164a54fb9bd63eee035fe98e5",
            "4e989e08dc52438d95a991ba441a49ec",
            "4f196f4eac44493ea5031fe7c9b2c06f",
            "51bf2ebe07e842f8bfc1a16871bb4308",
            "ecb070a84ebd47beaf4058299cb7c0b3",
            "5aa7e2d331cb41498420aec71f1225ea"
          ]
        },
        "id": "WsHt3nZqUsUd",
        "outputId": "d0c0ed26-57ca-4375-a90d-010fb440f4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/150 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "491ea75bd37648e2bc7769e7b50ff6d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.995790421962738}, {'label': 'POSITIVE', 'score': 0.004209598992019892}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9774223566055298}, {'label': 'POSITIVE', 'score': 0.02257763035595417}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9808201193809509}, {'label': 'POSITIVE', 'score': 0.0191799309104681}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9998254179954529}, {'label': 'NEGATIVE', 'score': 0.00017460808157920837}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9993558526039124}, {'label': 'POSITIVE', 'score': 0.0006440930301323533}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9996137022972107}, {'label': 'NEGATIVE', 'score': 0.0003863279416691512}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9995408058166504}, {'label': 'NEGATIVE', 'score': 0.00045919447438791394}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.8765423893928528}, {'label': 'NEGATIVE', 'score': 0.12345756590366364}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.8855456113815308}, {'label': 'POSITIVE', 'score': 0.11445437371730804}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9991662502288818}, {'label': 'POSITIVE', 'score': 0.0008337981998920441}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9936037659645081}, {'label': 'POSITIVE', 'score': 0.006396252661943436}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9975480437278748}, {'label': 'NEGATIVE', 'score': 0.0024519115686416626}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9680858254432678}, {'label': 'POSITIVE', 'score': 0.031914111226797104}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9871254563331604}, {'label': 'POSITIVE', 'score': 0.01287452969700098}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9996497631072998}, {'label': 'POSITIVE', 'score': 0.0003502107865642756}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9833865761756897}, {'label': 'NEGATIVE', 'score': 0.016613468527793884}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9981934428215027}, {'label': 'POSITIVE', 'score': 0.0018066131742671132}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9874591827392578}, {'label': 'NEGATIVE', 'score': 0.012540779076516628}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9939093589782715}, {'label': 'POSITIVE', 'score': 0.006090596318244934}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9755290150642395}, {'label': 'NEGATIVE', 'score': 0.02447102963924408}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.998664140701294}, {'label': 'POSITIVE', 'score': 0.0013358071446418762}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9682899713516235}, {'label': 'NEGATIVE', 'score': 0.03171003237366676}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9974470138549805}, {'label': 'NEGATIVE', 'score': 0.0025529609993100166}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9962782263755798}, {'label': 'POSITIVE', 'score': 0.0037217668723315}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9992232322692871}, {'label': 'NEGATIVE', 'score': 0.0007767813513055444}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9856629967689514}, {'label': 'POSITIVE', 'score': 0.014336975291371346}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.5730920433998108}, {'label': 'POSITIVE', 'score': 0.4269079864025116}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.999446451663971}, {'label': 'NEGATIVE', 'score': 0.0005535497330129147}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9944750666618347}, {'label': 'POSITIVE', 'score': 0.005524897947907448}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9996525049209595}, {'label': 'POSITIVE', 'score': 0.0003474587283562869}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9992215633392334}, {'label': 'POSITIVE', 'score': 0.0007784324116073549}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9253917932510376}, {'label': 'POSITIVE', 'score': 0.07460823655128479}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9997132420539856}, {'label': 'NEGATIVE', 'score': 0.0002867064322344959}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9996039271354675}, {'label': 'NEGATIVE', 'score': 0.00039609972736798227}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9996159076690674}, {'label': 'NEGATIVE', 'score': 0.0003840445133391768}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9997398257255554}, {'label': 'NEGATIVE', 'score': 0.0002601539599709213}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9995018243789673}, {'label': 'NEGATIVE', 'score': 0.0004982000682502985}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9990615248680115}, {'label': 'POSITIVE', 'score': 0.0009384789736941457}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9997496008872986}, {'label': 'NEGATIVE', 'score': 0.00025037716841325164}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.994482159614563}, {'label': 'POSITIVE', 'score': 0.005517901852726936}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9029324054718018}, {'label': 'POSITIVE', 'score': 0.09706760942935944}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9976333379745483}, {'label': 'POSITIVE', 'score': 0.0023666666820645332}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9994188547134399}, {'label': 'POSITIVE', 'score': 0.0005811591981910169}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9984598159790039}, {'label': 'NEGATIVE', 'score': 0.00154013279825449}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9976373910903931}, {'label': 'POSITIVE', 'score': 0.0023626575712114573}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9637463092803955}, {'label': 'POSITIVE', 'score': 0.03625369444489479}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9823880791664124}, {'label': 'NEGATIVE', 'score': 0.017611918970942497}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9957452416419983}, {'label': 'NEGATIVE', 'score': 0.004254797473549843}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.7168563008308411}, {'label': 'NEGATIVE', 'score': 0.28314366936683655}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9973593354225159}, {'label': 'POSITIVE', 'score': 0.0026406957767903805}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9998090863227844}, {'label': 'POSITIVE', 'score': 0.0001909544225782156}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9997749924659729}, {'label': 'POSITIVE', 'score': 0.00022506156528834254}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9983735084533691}, {'label': 'NEGATIVE', 'score': 0.0016264087753370404}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.996669590473175}, {'label': 'POSITIVE', 'score': 0.003330449340865016}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9997938275337219}, {'label': 'POSITIVE', 'score': 0.00020624521130230278}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9985861778259277}, {'label': 'POSITIVE', 'score': 0.001413826597854495}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9904554486274719}, {'label': 'NEGATIVE', 'score': 0.009544603526592255}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9066441655158997}, {'label': 'POSITIVE', 'score': 0.09335581213235855}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9988793730735779}, {'label': 'NEGATIVE', 'score': 0.001120658009313047}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9939385652542114}, {'label': 'POSITIVE', 'score': 0.006061447784304619}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9857037663459778}, {'label': 'POSITIVE', 'score': 0.014296204783022404}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9922439455986023}, {'label': 'NEGATIVE', 'score': 0.007756005972623825}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9981864094734192}, {'label': 'POSITIVE', 'score': 0.0018136106664314866}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.7297922968864441}, {'label': 'POSITIVE', 'score': 0.2702076733112335}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.999817430973053}, {'label': 'NEGATIVE', 'score': 0.00018265149265062064}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9867160320281982}, {'label': 'NEGATIVE', 'score': 0.013283888809382915}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9914361834526062}, {'label': 'POSITIVE', 'score': 0.008563831448554993}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.995232880115509}, {'label': 'POSITIVE', 'score': 0.004767114296555519}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.6256718635559082}, {'label': 'POSITIVE', 'score': 0.3743281364440918}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9985893368721008}, {'label': 'NEGATIVE', 'score': 0.0014106605667620897}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9482010006904602}, {'label': 'NEGATIVE', 'score': 0.05179905146360397}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9998666048049927}, {'label': 'NEGATIVE', 'score': 0.00013336505799088627}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9975797533988953}, {'label': 'POSITIVE', 'score': 0.0024202873464673758}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9938550591468811}, {'label': 'POSITIVE', 'score': 0.006144875660538673}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.998991072177887}, {'label': 'NEGATIVE', 'score': 0.001008910476230085}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.826283872127533}, {'label': 'POSITIVE', 'score': 0.17371612787246704}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9969145059585571}, {'label': 'NEGATIVE', 'score': 0.0030854898504912853}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.6956364512443542}, {'label': 'POSITIVE', 'score': 0.30436357855796814}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.999743640422821}, {'label': 'POSITIVE', 'score': 0.00025630780146457255}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9997569918632507}, {'label': 'NEGATIVE', 'score': 0.00024298181233461946}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9989790916442871}, {'label': 'NEGATIVE', 'score': 0.0010209729662165046}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9991600513458252}, {'label': 'NEGATIVE', 'score': 0.0008398983045481145}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9935615062713623}, {'label': 'POSITIVE', 'score': 0.006438474170863628}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9294766783714294}, {'label': 'NEGATIVE', 'score': 0.07052329182624817}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9748899340629578}, {'label': 'NEGATIVE', 'score': 0.0251100305467844}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9977772831916809}, {'label': 'NEGATIVE', 'score': 0.0022227312438189983}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9440058469772339}, {'label': 'NEGATIVE', 'score': 0.05599408596754074}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.9183108806610107}, {'label': 'NEGATIVE', 'score': 0.08168910443782806}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9914536476135254}, {'label': 'POSITIVE', 'score': 0.00854636263102293}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9762563705444336}, {'label': 'POSITIVE', 'score': 0.02374356985092163}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'POSITIVE', 'score': 0.6376935839653015}, {'label': 'NEGATIVE', 'score': 0.3623064160346985}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9944214224815369}, {'label': 'POSITIVE', 'score': 0.005578538868576288}]\n",
            "Type of sentiment_outputs: <class 'list'>\n",
            "First element of sentiment_outputs: [{'label': 'NEGATIVE', 'score': 0.9865358471870422}, {'label': 'POSITIVE', 'score': 0.01346419658511877}]\n",
            "Model saved to ./gpt2-imdb-ppo-bf246eb3/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    test_prompts = [\n",
        "        \"This movie was absolutely fantastic because\",\n",
        "        \"The storyline seemed a bit off, but\",\n",
        "        \"I heard great reviews, yet\"\n",
        "    ]\n",
        "    evaluate_model(\"gpt2-imdb-ppo-latest\", test_prompts)"
      ],
      "metadata": {
        "id": "FPo7x6TZUtJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "outputId": "e9854ece-35f8-4c93-8424-bb3c4fff1763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "gpt2-imdb-ppo-latest is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/gpt2-imdb-ppo-latest/resolve/main/tokenizer_config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1642\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1644\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1532\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1447\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1449\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m429\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    458\u001b[0m             )\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6822b3d4-137348fc0ed7bbed73c7c94e;74ae5186-f390-4866-be0c-a051e6bd4655)\n\nRepository Not Found for url: https://huggingface.co/gpt2-imdb-ppo-latest/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3e70992ff793>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"I heard great reviews, yet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ]\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gpt2-imdb-ppo-latest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_prompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-2f70a95848a0>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model_dir, prompts)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Evaluates the fine-tuned model on sample prompts.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     gen_pipe = pipeline(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         ) from e\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: gpt2-imdb-ppo-latest is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ]
    }
  ]
}